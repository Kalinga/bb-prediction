{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 88 from C header, got 96 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "import pickle\n",
    "# for scaling and inverse_transform\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"30f_future-model.h5\"\n",
    "model = load_model(model_path)\n",
    "n_seq = 30\n",
    "n_seq_future = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join, basename, abspath, exists\n",
    "from os import listdir, makedirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaad_path = \"/home/kara9147/jaad2\"\n",
    "annotation_path = join(jaad_path, 'annotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaad_data import JAAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = JAAD(data_path = jaad_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play():\n",
    "    global batch\n",
    "    img_width, img_height = 960, 540\n",
    "    start_time_video = time.time()\n",
    "    clip_path = \"/home/kara9147/JAAD/JAAD_clips/\" + vid + \".mp4\"\n",
    "    cap = cv2.VideoCapture(clip_path)\n",
    "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print( length, frames[0] )\n",
    "    \n",
    "    # Time to read all frames, predict and put bounding boxes around them, and show them.\n",
    "    i = 0\n",
    "    total_time = 0.0\n",
    "    pred = True\n",
    "\n",
    "    # Capture frame-by-frame\n",
    "    ret = True\n",
    "    \n",
    "    while(ret and i <  frames[0] + n_seq):\n",
    "        ret, origimg = cap.read()\n",
    "        i += 1\n",
    "    print(i)\n",
    "    i = 0\n",
    "    while(ret and i < lstm_seq.shape[0] - (n_seq + n_seq_future) -1):\n",
    "        ret, origimg = cap.read()\n",
    "        batch = lstm_seq[i:i + n_seq]\n",
    "        print(batch)\n",
    "       \n",
    "        i = i + 1\n",
    "        #print(\"Processing {} th frame\".format(i))\n",
    "        if (ret != False ):\n",
    "            #print(img.shape)\n",
    "            img = cv2.resize(origimg, (img_width, img_height))\n",
    "            current = time.time()\n",
    "            ##################################PREDICTION######################\n",
    "            y_hat = model.predict(np.expand_dims(batch, axis=0))\n",
    "            print(y_hat)\n",
    "\n",
    "            #batch =  np.delete(batch, 0, axis = 0)\n",
    "            #batch =  np.append(batch, y_hat, axis = 0)\n",
    "            #print(len(batch))\n",
    "            \n",
    "            end = time.time()\n",
    "            diff = end - current\n",
    "            total_time  = total_time  + diff\n",
    "            #print(end - current)\n",
    "            #print(\"Time spent for predicting: {0}\".format(diff))\n",
    "\n",
    "            # 4: Decode the raw prediction `y_pred`\n",
    "            inv_yhat = scaler.inverse_transform(y_hat)[0]\n",
    "            print(inv_yhat)\n",
    "            #inv_yhat = y_hat[0]\n",
    "           \n",
    "            np.set_printoptions(precision=2, suppress=True, linewidth=90)\n",
    "            # print(\"Predicted boxes:\\n\")\n",
    "            # print('   class   conf xmin   ymin   xmax   ymax')\n",
    "\n",
    "            #print(y_pred_decoded)\n",
    "\n",
    "            #print(time.time() - start_time)\n",
    "\n",
    "            if pred:\n",
    "                xmin = int(inv_yhat[0] / 2)\n",
    "                ymin = int(inv_yhat[1] / 2)\n",
    "                xmax = int(inv_yhat[2] / 2)\n",
    "                ymax = int(inv_yhat[3] / 2)\n",
    "            else:\n",
    "                xmin = int(bb_cross[ped_b[ped_index]][i][0] / 2)\n",
    "                ymin = int(bb_cross[ped_b[ped_index]][i][1] / 2)\n",
    "                xmax = int(bb_cross[ped_b[ped_index]][i][2] / 2)\n",
    "                ymax = int(bb_cross[ped_b[ped_index]][i][3] / 2)\n",
    "\n",
    "            print((xmin, ymin))\n",
    "            print((xmax, ymax))\n",
    "            # 1920x1080\n",
    "            #cv2.rectangle(img, (0,  0 ), (1910, 1070), (255, 0, 0), 2)\n",
    "\n",
    "            # Draw the predicted boxes in blue\n",
    "            cv2.rectangle(img, (xmin, ymin), (xmax, ymax ), (255, 0, 0), 1)\n",
    "\n",
    "            #xmin_ = int (df[i:i+1][0] / 2)\n",
    "            #ymin_ = int (df[i:i+1][1] / 2)\n",
    "            #xmax_ = int (df[i:i+1][2] / 2)\n",
    "            #ymax_ = int (df[i:i+1][3] / 2)\n",
    "            \n",
    "            xmin_ = int (df[i+n_seq -1 : i+n_seq][0] / 2)\n",
    "            ymin_ = int (df[i+n_seq -1 : i+n_seq][1] / 2)\n",
    "            xmax_ = int (df[i+n_seq -1 : i+n_seq][2] / 2)\n",
    "            ymax_ = int (df[i+n_seq -1 : i+n_seq][3] / 2)\n",
    "            \n",
    "            # Draw the present boxes in green\n",
    "            cv2.rectangle(img, (xmin_, ymin_), (xmax_, ymax_ ), (0, 255, 0), 1)\n",
    "            \n",
    "            # Draw the actual future boxes in red\n",
    "            cv2.rectangle(img, (int(df[i+(n_seq + n_seq_future) -1 : i + (n_seq + n_seq_future)][0] / 2),\n",
    "                          int(df[i+(n_seq + n_seq_future) -1 : i+ (n_seq + n_seq_future)][1] / 2)),\n",
    "                          (int(df[i+(n_seq + n_seq_future) -1 : i+ (n_seq + n_seq_future)][2] / 2),\n",
    "                          int(df[i+(n_seq + n_seq_future) -1 : i+ (n_seq + n_seq_future)][3] / 2))\n",
    "                          , (0, 0,255), 1)\n",
    "\n",
    "\n",
    "            # Display the resulting frame\n",
    "            cv2.imshow('frame',img)\n",
    "\n",
    "            # waitKey: 0, wait indefinitely\n",
    "            if cv2.waitKey(33) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    end_time_video = time.time()\n",
    "    print(\"No of frames: {}\".format(i))\n",
    "    print(\"Total Time: {}\".format(total_time))\n",
    "    print(\"fps: {}\".format(i / (total_time)))\n",
    "\n",
    "    # When everything done, release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = \"video_0309\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno = imdb._get_annotations(vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1920"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno['width']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_309_2437b\n",
      "0_309_2441b\n",
      "0_309_2439b\n",
      "0_309_2434b\n",
      "0_309_2436b\n",
      "0_309_2435b\n",
      "0_309_2440b\n",
      "0_309_2438b\n",
      "['0_309_2437b', '0_309_2441b', '0_309_2439b', '0_309_2434b', '0_309_2436b', '0_309_2435b', '0_309_2440b', '0_309_2438b']\n"
     ]
    }
   ],
   "source": [
    "bb_cross={}\n",
    "ped_b = [k for k,v in anno[\"ped_annotations\"].items() if k.endswith('b')]\n",
    "\n",
    "for i, p in enumerate(ped_b):\n",
    "    #if (1 in anno[\"ped_annotations\"][p][\"behavior\"][\"cross\"]):\n",
    "        bb_cross[p] = (anno[\"ped_annotations\"][p][\"bbox\"])\n",
    "        print(p)\n",
    "print(ped_b)\n",
    "#for k,v in bb_cross.items():\n",
    "#    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "ped_index = 0\n",
    "lstm_seq =  bb_cross[ped_b[ped_index]]\n",
    "frames = (anno['ped_annotations'][ped_b[ped_index]]['frames'][0], len(anno['ped_annotations'][ped_b[ped_index]]['frames']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 20)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames\n",
    "#len(lstm_seq)\n",
    "#l = [k for k,v in anno['ped_annotations'][ped_b[ped_index]].items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(lstm_seq)\n",
    "df = df.astype('float32')\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    xmin_ = int (df[i:i+1][0] / 2)\n",
    "    ymin_ = int (df[i:i+1][1] / 2)\n",
    "    xmax_ = int (df[i:i+1][2] / 2)\n",
    "    ymax_ = int (df[i:i+1][3] / 2)\n",
    "    #print(i, xmin_, ymin_, xmax_, ymax_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle_in = open(\"min-max-scaler.pkl\",\"rb\")\n",
    "#scaler = pickle.load(pickle_in)\n",
    "#print(type(scaler))\n",
    "#print(scaler.data_max_)\n",
    "#print(scaler.data_min_)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "lstm_seq = scaler.fit_transform(lstm_seq)\n",
    "#batch = scaler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lstm_seq.shape[0]\n",
    "#frames[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 0\n",
      "30\n",
      "No of frames: 0\n",
      "Total Time: 0.0\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-425fd712de3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-7398a5aa2d8a>\u001b[0m in \u001b[0;36mplay\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No of frames: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total Time: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fps: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;31m# When everything done, release the capture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
